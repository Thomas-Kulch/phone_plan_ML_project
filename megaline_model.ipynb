{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction to Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-radius: 15px; border: 3px solid skyblue; padding: 15px;\">\n",
    "    \n",
    "The task:\n",
    "    \n",
    "    - Mobile carrier Megaline has found out that many of their subscribers use legacy plans. They want to develop a model that would analyze subscribers' behavior and recommend one of Megaline's newer plans: Smart or Ultra. \n",
    "\n",
    "I have behavior data about subscribers who have already switched to the new plans. I will need to use classification to develop a model that will pick the right plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data and Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data and analyze\n",
    "df = pd.read_csv('/datasets/users_behavior.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Description\n",
    "\n",
    "сalls — number of calls\n",
    "\n",
    "minutes — total call duration in minutes\n",
    "\n",
    "messages — number of text messages\n",
    "\n",
    "mb_used — Internet traffic used in MB\n",
    "\n",
    "is_ultra — plan for the current month (Ultra - 1, Smart - 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "# check the dataframe for missing values or data types that need to be changed\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [calls, minutes, messages, mb_used, is_ultra]\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for duplicates\n",
    "df[df.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:skyblue\">Observations</span>\n",
    "<div style=\"border-radius: 15px; border: 3px solid skyblue; padding: 15px;\">\n",
    "This dataset has been cleaned in another project and there are no missing values, incorrect data types, or duplicates. \n",
    "    \n",
    "The data is ready to be used in a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into Training, Test, and Validation sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-radius: 15px; border: 3px solid skyblue; padding: 15px;\">\n",
    "    I'll be splitting the data into a 3:1:1 ratio. I want to leave a good size for the training set as it is already pretty small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the is_ultra field will be our target because we are trying to see if customers have the correct plan, with the rest being the features\n",
    "\n",
    "features = df.drop(['is_ultra'],axis=1)\n",
    "target = df['is_ultra']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into training and test\n",
    "features_train,features_test,target_train,target_test = train_test_split(features,target,\n",
    "                                                                         test_size=0.25,\n",
    "                                                                         random_state=12345)\n",
    "\n",
    "#split the previously split data into training and validation sets\n",
    "features_train,features_valid,target_train,target_valid = train_test_split(features_train,target_train,\n",
    "                                                                           test_size=0.25,\n",
    "                                                                           random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup models to Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "To determine the optimal Decision Tree model, I will create a function that will test out different hyperparameters like \n",
    "max_depth, _min_samples_split and min_samples_leaf and return the Decision Tree model that has the best accuracy.\n",
    "\n",
    "I will then compare the best Decision Tree model with the best models from the other two categories.\n",
    "\n",
    "The ideal min_samples_split values are between 2-40 and the ideal min_samples_leaf values are between 1-20\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "def best_decision_tree(features_train,features_test,target_train,target_test):\n",
    "    best_model = None\n",
    "    best_result = 0\n",
    "    \n",
    "    for depth in range(1,11):\n",
    "        for split in range(2,41):\n",
    "            for leaf in range(1,21):\n",
    "                model = DecisionTreeClassifier(random_state=12345,\n",
    "                                               max_depth=depth,\n",
    "                                               min_samples_split=split,\n",
    "                                               min_samples_leaf=leaf) # initiate the model to be tested\n",
    "                model.fit(features_train,target_train) # train the model\n",
    "                predictions = model.predict(features_test)\n",
    "                result = accuracy_score(target_test,predictions) # grab the accuracy score for each model to be compared\n",
    "                \n",
    "                if result > best_result:\n",
    "                    best_model = model\n",
    "                    best_result = result\n",
    "                    \n",
    "    return best_model, best_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign the model to a variable to be compared later\n",
    "best_decision_tree = best_decision_tree(features_train,features_test,target_train,target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Similar to the Decision Tree model, I will create a function that will test out different hyperparameters like \n",
    "n_estimators, max_depth, _min_samples_split and min_samples_leaf and return the Random Forest model that has the best accuracy.\n",
    "\n",
    "I will then compare the best Random Forest model with the best models from the other two categories.\n",
    "\n",
    "'''\n",
    "\n",
    "def best_random_forest(features_train,features_test,target_train,target_test):\n",
    "    best_model = None\n",
    "    best_result = 0\n",
    "    \n",
    "    for est in range(1,11):\n",
    "        for depth in range(1,6):\n",
    "            for split in range(2,21):\n",
    "                for leaf in range(1,11):\n",
    "                    model = RandomForestClassifier(random_state=12345,\n",
    "                                                   n_estimators=est,\n",
    "                                                   max_depth=depth,\n",
    "                                                   min_samples_split=split,\n",
    "                                                   min_samples_leaf=leaf)\n",
    "                    model.fit(features_train,target_train) # train the model\n",
    "                    predictions = model.predict(features_test)\n",
    "                    result = accuracy_score(target_test,predictions) # grab the accuracy score for each model to be compared\n",
    "                \n",
    "                    if result > best_result:\n",
    "                        best_model = model\n",
    "                        best_result = result\n",
    "                        \n",
    "    return best_model, best_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign the model to a variable to be compared later\n",
    "best_random_forest = best_random_forest(features_train,features_test,target_train,target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "I will create a function that will test out different hyperparameters like \n",
    "solvers and C values and return the Logistic Regression model that has the best accuracy.\n",
    "\n",
    "I'm not including a penalty list in this because some values don't work with certain solvers.\n",
    "\n",
    "I will then compare the best Logistic Regression model with the best models from the other two categories.\n",
    "\n",
    "'''\n",
    "\n",
    "def best_logistic_regression(features_train,features_test,target_train,target_test):\n",
    "    best_model = None\n",
    "    best_score = 0\n",
    "    solver_list = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "    c_list = [0.01,0.1,1,10,100]\n",
    "    \n",
    "    for c in c_list:\n",
    "        for solver in solver_list:\n",
    "            model = LogisticRegression(random_state=12345,solver=solver,penalty='l2',C=c)\n",
    "            model.fit(features_train,target_train)   \n",
    "            score_valid = model.score(features_test,target_test)  \n",
    "                \n",
    "            if score_valid > best_score:\n",
    "                best_model = model\n",
    "                best_score = score_valid\n",
    "                    \n",
    "    return best_model, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DecisionTreeClassifier(max_depth=7, min_samples_leaf=11, random_state=12345),\n",
       " 0.7978227060653188)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(RandomForestClassifier(max_depth=5, min_samples_split=14, n_estimators=1,\n",
       "                        random_state=12345),\n",
       " 0.80248833592535)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(LogisticRegression(C=0.01, random_state=12345, solver='newton-cg'),\n",
       " 0.76049766718507)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#assign the model to a variable and display the models accuracies side by side and their optimal hyperparameters\n",
    "best_logistic_regression = best_logistic_regression(features_train,features_valid,target_valid,target_test)\n",
    "\n",
    "display(best_decision_tree) #The accuracy of the best Decision Tree model is 0.7978227060653188\n",
    "display(best_random_forest) #The accuracy of the best Random Forest model is 0.80248833592535\n",
    "display(best_logistic_regression) #The accuracy of the best Logistic Regression model is 0.7223300970873786"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:skyblue\">Findings</span>\n",
    "<div style=\"border-radius: 15px; border: 3px solid skyblue; padding: 15px;\">\n",
    "    \n",
    "    After finding the best model for Decision Tree, Random Forest, and Logistic Regression, it looks like although the Random Forest is the slowest to run, it is a little more accurate than the Decision Tree and should be used as the model for this task.\n",
    "    \n",
    "    The best Logistic Regression model did not cross our accuracy threshold of 0.75 and should not be considered over the other two models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=5, min_samples_split=14, n_estimators=1,\n",
       "                       random_state=12345)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#split the model from it's accuracy value to use for quality check with validation set\n",
    "model, valid_accuracy = best_random_forest\n",
    "display(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest Model against Validation data set: 0.7669902912621359\n"
     ]
    }
   ],
   "source": [
    "#train the random forest model and test it's accuracy against the validation set\n",
    "model.fit(features_train,target_train)\n",
    "predictions = model.predict(features_test)\n",
    "test_accuracy = accuracy_score(predictions,target_test)\n",
    "\n",
    "print('Accuracy of Random Forest Model against Validation data set:',test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:skyblue\">Observations</span>\n",
    "<div style=\"border-radius: 15px; border: 3px solid skyblue; padding: 15px;\">\n",
    "    \n",
    "The accuracy of the Random Forest model against the validation dataset is lower than our test dataset, but still above our 0.75 threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores: [0.78398058 0.77615572 0.79805353 0.79075426 0.8053528 ]\n",
      "Average Cross-Validation Accuracy: 0.7908593768454869\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "I will use a cross validation  check on the Random Forest Classifier for the sanity check. I will also visualize\n",
    "the feature importance to see which features are most influential in making predictions.\n",
    "'''\n",
    "\n",
    "# Perform cross-validation to get average accuracy\n",
    "cv_scores = cross_val_score(model, features_train, target_train, cv=5)\n",
    "print(\"Cross-Validation Scores:\", cv_scores)\n",
    "print(\"Average Cross-Validation Accuracy:\", cv_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualize feature importance to see which features are most influential in making predictions\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.barh(range(features.shape[1]), model.feature_importances_, align='center')\n",
    "plt.yticks(range(features.shape[1]),features.columns)\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Feature Importances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:skyblue\">Observations</span>\n",
    "<div style=\"border-radius: 15px; border: 3px solid skyblue; padding: 15px;\">\n",
    "    \n",
    "Based on our findings, a cross-validation mean of 79% means that, on average, the model correctly predicts the target variable for 79% of the samples across different cross-validation folds.\n",
    "\n",
    "While 79% is good and above our accuracy threshold, there is room for improvement in the model.\n",
    "\n",
    "We also find that in terms of features, minutes and mb_used are the most important features and are most influential in making predictions.\n",
    "\n",
    "Overall, an accuracy of 79% means that the model performs generally well on average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-radius: 15px; border: 3px solid skyblue; padding: 15px;\">\n",
    "    \n",
    "    - I tested 3 different classification models using the features, target, and validation datasets from the Megaline Mobile data.\n",
    "    \n",
    "    - While the Decision Tree and Random Forest models performed similarly, the Random Forest model slightly edged it out and the Logisitic Regression model did not come anywhere close in terms of accuracy.\n",
    "    \n",
    "    - I performed a sanity check on the Random Forest model and got a 79% average accuracy and found that the minutes and mb_used features are the most important and are most influential in making predictions for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
